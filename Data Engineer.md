# DATA Engineer at Wenea

## The company

Wenea Services is a young company founded in 2017, part of the
Diggia group. Diggia goal is to be as an integrator of services 
and innovative solutions in the field of telecommunications, 
photovoltaic energy and long-term viable mobility.

In Wenea you will be part of an ongoing ecosystem that provides
services for a sustainable, electric mobility,
using renewable energies and technologies.
We are looking for people with a passion in building products and services
that help in the continuous pursuit for a better green present and a 
sustainable future.

## The project

This green future needs work to be done now. And currently, one of
the biggest problems with the electric mobility is the low amount of
active electric charge points . What's good about the iteratively
higher range of the EVs, if their drivers need to fork their route in
order to charge and be able to have enough energy to end their
journey? Alongside a bigger energy waste, the drivers are more
exposed to road hazards by driving useless kilometers. This is an
issue not only present on medium distance journeys, it also affects
the people that uses their car frequently, but doesn't go that far. A
low amount of charge points, that are far from the destination of a
person daily commute, makes it difficult to justify the entry cost of
electric mobility for the common driver. This is why we started
working on **Wenea Platform**, our own fleet of charge
points that are managed by us.

This is only but a small glance at the scope of Wenea Platform.
You will be an active part of the continuous evolution of the
project.

## Perks

As you can already guess, we love sustainability. We don't want
anyone to drive more than what it's needed. That's also why we offer
a **full remote** position. You can work from the beach, from the mountains, 
or from your local hometown that you miss. Post covid you could also come to
any of our offices in Madrid or CÃ¡ceres. Either if you come or not, you will
always feel connected with the team.

We ask you to be proactive, self organized. We believe that when a
company asks for something, they have to give something back. That's
why we also offer you **flexible schedule**. Your work
will not be valued depending on how many and in what hours you
completed it. What we are proud of is the quality of it.

We also offer **health insurance**, **flexible
remuneration** and a **career plan**, which
includes formation. You get to choose what you want to learn, what
technical books you read and the path you want to follow in your
professional trajectory.

## What will you do

- Design and implement ETL batch and streaming pipelines following the needs of the business team.

- Design data warehouses architecture and improve the already existing ones.

- Automate deployments of the data pipelines following the Continuous Delivery methodology.

- Communicate with the business team to understand the ever evolving data needs.  

- Give value to the raw data and help the company progress in a data-centric world.

- Improve yourself and your abilities day by day.

## Requirements

- A proactive and self-managing professional.

- Demonstrable experience in the data sector. Let it be building ETL pipelines, data models, data warehouse 
architectures or machine learning models.

- Knowledge of data processing frameworks and tools. (Spark, Apache Airflow, Kafka, ELK stack, Pandas and similar 
tools)

- Clear concepts of relational and no relational databases. (SQL dbms, MongoDB, Elasticsearch, redis)

- Deep understanding in python and bash scripting.

- Experience and passion with Linux based distributions.

- High level understanding on collaborative VCS workflow
   (Branching, Pull Requests, Gitflow)

- Experience with Continuous Integration and Delivery concepts, processes and tools (Jenkins, GitHub actions, ansible).

- Applicable experience with Agile frameworks, in particular with
   Scrum.

## Desirable

- Knowledge about Azure, Amazon Web Services and cloud computing.

- Experience with full stack programming.

- Hands-on experience with business intelligence tools (Power BI, Tableau, Qlik...)

- Experience with graph based databases (Neo4j, Graphdb)

## How to apply

Refer to [Applying in the README](README.md#Applying).
